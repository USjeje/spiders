import scrapy
import time
import re
from urllib.parse import quote
from scrapy_playwright.page import PageMethod
from ..models import VintedItem


class VintedSpider(scrapy.Spider):
    name = 'vinted'
    allowed_domains = ['vinted.co.uk']
    custom_settings = {
        'CONCURRENT_REQUESTS': 32,  # æé«˜å¹¶å‘ä»¥åŠ é€Ÿè¯¦æƒ…é¡µæŠ“å–
    }

    def start_requests(self):
        search_text = getattr(self, 'search_text', '').strip()
        if not search_text:
            self.logger.error("âŒ é”™è¯¯: ç¼ºå°‘ search_text å‚æ•°")
            raise ValueError("âŒ è¯·ä½¿ç”¨ -a search_text=å…³é”®è¯ è¿è¡Œçˆ¬è™«")

        encoded_search_text = quote(search_text)
        self.logger.info(f"ğŸ” æœç´¢å…³é”®è¯: {search_text}")

        url = f"https://www.vinted.co.uk/catalog?search_text={encoded_search_text}&order=newest_first&page=1"
        yield scrapy.Request(
            url=url,
            callback=self.parse,
            meta={
                "playwright": True,
                "playwright_page_methods": [
                    PageMethod("wait_for_selector", "a.new-item-box__overlay"),
                    PageMethod("evaluate", "window.scrollTo(0, document.body.scrollHeight);"),
                    PageMethod("wait_for_timeout", 5000)
                ]
            }
        )

    def parse(self, response):
        products = response.css('a.new-item-box__overlay')
        search_text = getattr(self, 'search_text', '').strip()

        for product in products:
            item = {
                'url': response.urljoin(product.attrib.get('href')),
                'title': product.attrib.get('title', ''),
                'product_id': self.extract_product_id(product),
                'search_text': search_text,
                'shipping_fee': None,  # åˆå§‹åŒ–ä¸ºNone
                'price': None
            }
            title_data = self.parse_title(item['title'])
            item.update(title_data)

            # ç¬¬ä¸€é˜¶æ®µï¼šå¿«é€Ÿä¿å­˜åŸºç¡€æ•°æ®
            self.save_to_mongo(item, is_initial=True)

            # ç¬¬äºŒé˜¶æ®µï¼šå¼‚æ­¥è·å–è¿è´¹
            yield scrapy.Request(
                url=item['url'],
                callback=self.parse_shipping,
                meta={
                    "playwright": True,
                    "playwright_page_methods": [
                        PageMethod("wait_for_selector", "h3[data-testid='item-shipping-banner-price']"),
                        PageMethod("wait_for_timeout", 2000)
                    ],
                    "item": item  # ä¼ é€’itemåˆ°è¯¦æƒ…é¡µè§£æ
                },
                priority=1  # æé«˜ä¼˜å…ˆçº§ä»¥åŠ é€Ÿå¤„ç†
            )

    def parse_shipping(self, response):
        item = response.meta['item']
        shipping_text = response.css(
            'h3[data-testid="item-shipping-banner-price"]::text'
        ).get()

        # è§£æè¿è´¹ï¼ˆä¾‹å¦‚ï¼š"from Â£5.00" -> 5.00ï¼‰
        self.logger.error(shipping_text)
        shipping_fee = self.extract_shipping_fee(shipping_text)
        item['shipping_fee'] = shipping_fee

        # è®¡ç®—æœ€ç»ˆä»·æ ¼ï¼ˆæ ¹æ®ä¸šåŠ¡é€»è¾‘è°ƒæ•´ï¼‰
        if item.get('platform_fee', 0):
            item['price'] = item.get('platform_fee', 0) + shipping_fee

        # æ›´æ–°æ•°æ®åº“è®°å½•
        self.save_to_mongo(item, is_initial=False)
        return item

    def extract_shipping_fee(self, text):
        if not text:
            return 0.0
        match = re.search(r'Â£([\d,]+\.\d{2})', text)
        return float(match.group(1).replace(',', '')) if match else 0.0

    def extract_product_id(self, element):
        testid = element.attrib.get('data-testid', '')
        return testid.split('--')[0].split('-')[-1] if testid else ''

    def parse_title(self, title):
        prices = re.findall(r'Â£([\d,]+\.\d{2})', title)
        clean_price = lambda s: float(s.replace(',', '')) if s else None

        return {
            'brand': re.search(r'brand:\s*([^,]+)', title).group(1).strip() if 'brand:' in title else None,
            'condition': re.search(r'condition:\s*([^,]+)', title).group(1).strip() if 'condition:' in title else None,
            'seller_price': clean_price(prices[0]) if len(prices) > 0 else None,
            'platform_fee': clean_price(prices[1]) if len(prices) > 1 else None,
        }

    def save_to_mongo(self, item, is_initial):
        update_data = {
            'set__title': item['title'],
            'set__product_id': item['product_id'],
            'set__brand': item['brand'],
            'set__condition': item['condition'],
            'set__search_text': item['search_text'],
            'set__seller_price': item['seller_price'],
            'set__platform_fee': item['platform_fee'],
        }

        if not is_initial:  # ç¬¬äºŒé˜¶æ®µæ›´æ–°è¿è´¹å’Œä»·æ ¼
            update_data.update({
                'set__shipping_fee': item['shipping_fee'],
                'set__price': item['price']
            })

        try:
            VintedItem.objects(url=item['url']).update_one(
                **update_data,
                upsert=True
            )
            log_msg = "åˆç¨¿ä¿å­˜" if is_initial else "è¿è´¹æ›´æ–°"
            self.logger.info(f"âœ… {log_msg}æˆåŠŸ: {item['url']}")
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")